# -*- coding: utf-8 -*-
"""Bert_toxicity_tunning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h-Mf88R2v58_7Z_5dyUIIJ3J4sknh9Qp
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
path ="/content/gdrive/My Drive/Colab Notebooks/jigsaw-unintended-bias-in-toxicity-classification/"
filename = "train.csv"
train_data  = pd.read_csv(path+filename)

!pip install pytorch-pretrained-bert

from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch
from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Converting the lines to BERT format
# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming
from tqdm import tqdm, tqdm_notebook
import numpy as np
def convert_lines(example, max_seq_length,tokenizer):
    max_seq_length -=2
    all_tokens = []
    longer = 0
    for text in tqdm_notebook(example):
        tokens_a = tokenizer.tokenize(text)
        if len(tokens_a)>max_seq_length:
            tokens_a = tokens_a[:max_seq_length]
            longer += 1
        one_token = tokenizer.convert_tokens_to_ids(["[CLS]"]+tokens_a+["[SEP]"])+[0] * (max_seq_length - len(tokens_a))
        all_tokens.append(one_token)
    print(longer)
    return np.array(all_tokens)

import pandas as pd
seed = 6666
train_size=80000#0                         #Train size 
valid_size= 10000#0                          #Validation Size
MAX_SEQUENCE_LENGTH = 128
train_df = train_data.sample(train_size+valid_size,random_state=seed)
print('loaded %d records' % len(train_df))

# Make sure all comment_text values are strings
train_df['comment_text'] = train_df['comment_text'].astype(str) 

sequences = convert_lines(train_df["comment_text"],MAX_SEQUENCE_LENGTH,tokenizer)
train_df=train_df.fillna(0)
# List all identities
identity_columns = [
    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',
    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']
y_columns=['target']

train_df = train_df.drop(['comment_text'],axis=1)
# convert target to 0,1
train_df['target']=(train_df['target']>=0.5).astype(float)

X = sequences[:train_size]                
y = train_df[y_columns].values[:train_size]
X_val = sequences[train_size:]                
y_val = train_df[y_columns].values[train_size:]

test_df=train_df.tail(valid_size).copy()
train_df=train_df.head(train_size)

import torch
import torch.nn as nn
import torch.utils.data
import torch.nn.functional as F
train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))

path = "/content/gdrive/My Drive/bert_pytorch.bin"
EPOCHS = 1
lr=2e-5
batch_size = 32
accumulation_steps=1
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed(seed)
torch.backends.cudnn.deterministic = True

device=torch.device('cuda')

model = BertForSequenceClassification.from_pretrained("bert-base-uncased",cache_dir=None,num_labels=len(y_columns))
model.zero_grad()
model = model.to(device)
param_optimizer = list(model.named_parameters())
no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']
optimizer_grouped_parameters = [
    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},
    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}
    ]
train = train_dataset
num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)

optimizer = BertAdam(optimizer_grouped_parameters,
                     lr=lr,
                     warmup=0.05,
                     t_total=num_train_optimization_steps)

model=model.train()

tq = tqdm_notebook(range(EPOCHS))
for epoch in tq:
    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
    avg_loss = 0.
    avg_accuracy = 0.
    lossf=None
    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)
    for i,(x_batch, y_batch) in tk0:
        optimizer.zero_grad()
        y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)
        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))
        loss.backward()
        if (i+1) % accumulation_steps == 0:  #Not used? # Wait for several backward steps
            optimizer.step()                            # Now we can do an optimizer step
            optimizer.zero_grad()
        if lossf:
            lossf = 0.98*lossf+0.02*loss.item()
        else:
            lossf = loss.item()
        tk0.set_postfix(loss = lossf)
        avg_loss += loss.item() / len(train_loader)
        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)
    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)


torch.save(model.state_dict(), path)

model_save_name = "bert_pytorch2.bin"
path = F"/content/gdrive/My Drive/{model_save_name}"
torch.save(model.state_dict(), path)

model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=len(y_columns))
model.load_state_dict(torch.load(path ))
model.to(device)

for param in model.parameters():
    param.requires_grad=False
model.eval()
valid_preds = np.zeros((len(X_val)))
valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))
valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)

tk0 = tqdm_notebook(valid_loader)
for i,(x_batch,)  in enumerate(tk0):
    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)
    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()

valid_preds[1000:2000]

# From baseline kernel

from sklearn import metrics
from sklearn import model_selection
def calculate_overall_auc(df, model_name):
    true_labels = df[TOXICITY_COLUMN]>0.5
    predicted_labels = df[model_name]
    return metrics.roc_auc_score(true_labels, predicted_labels)

def power_mean(series, p):
    total = sum(np.power(series, p))
    return np.power(total / len(series), 1 / p)

def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):
    bias_score = np.average([
        power_mean(bias_df[SUBGROUP_AUC], POWER),
        power_mean(bias_df[BPSN_AUC], POWER),
        power_mean(bias_df[BNSP_AUC], POWER)
    ])
    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)



SUBGROUP_AUC = 'subgroup_auc'
BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative
BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive

def compute_auc(y_true, y_pred):
    try:
        return metrics.roc_auc_score(y_true, y_pred)
    except ValueError:
        return np.nan

def compute_subgroup_auc(df, subgroup, label, model_name):
    subgroup_examples = df[df[subgroup]>0.5]
    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])

def compute_bpsn_auc(df, subgroup, label, model_name):
    """Computes the AUC of the within-subgroup negative examples and the background positive examples."""
    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]
    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]
    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)
    return compute_auc(examples[label]>0.5, examples[model_name])

def compute_bnsp_auc(df, subgroup, label, model_name):
    """Computes the AUC of the within-subgroup positive examples and the background negative examples."""
    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]
    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]
    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)
    return compute_auc(examples[label]>0.5, examples[model_name])

def compute_bias_metrics_for_model(dataset,
                                   subgroups,
                                   model,
                                   label_col,
                                   include_asegs=False):
    """Computes per-subgroup metrics for all subgroups and one model."""
    records = []
    for subgroup in subgroups:
        record = {
            'subgroup': subgroup,
            'subgroup_size': len(dataset[dataset[subgroup]>0.5])
        }
        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)
        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)
        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)
        records.append(record)
    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)

test_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()
# for a in test_df[MODEL_NAME]:
#   if a> .5:
#     print (a)
print(test_df[MODEL_NAME].describe())

print(test_df[MODEL_NAME].first_valid_index())

MODEL_NAME = 'model1'
test_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()
TOXICITY_COLUMN = 'target'
bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')
bias_metrics_df
get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))

import json
with open('/content/gdrive/My Drive/Colab Notebooks/jigsaw-unintended-bias-in-toxicity-classification/comments_videos_pewdiepie_4000.json') as json_data:
  d = json.load(json_data)
predict_comments = d[10]["comments"]

model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=len(y_columns))
model.load_state_dict(torch.load(path ))
model.to(device)

MAX_SEQUENCE_LENGTH = 128
# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

X_pew = convert_lines(predict_comments,MAX_SEQUENCE_LENGTH,tokenizer)

for param in model.parameters():
    param.requires_grad=False
model.eval()
valid_preds_pews = np.zeros((len(X_pew)))
valid_pews = torch.utils.data.TensorDataset(torch.tensor(X_pew,dtype=torch.long))
valid_loader_pews = torch.utils.data.DataLoader(valid_pews, batch_size=32, shuffle=False)

tk0 = tqdm_notebook(valid_loader_pews)
for i,(x_batch,)  in enumerate(tk0):
    pred_pews = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)
    valid_preds_pews[i*32:(i+1)*32]=pred_pews[:,0].detach().cpu().squeeze().numpy()

test_df_pews=torch.sigmoid(torch.tensor(valid_preds_pews)).numpy()

print(np.mean(test_df_pews))

toxic = ([v for v in test_df_pews if v > .5])
print(len(toxic))
count = 0
for i in range(len(test_df_pews)):
  if test_df_pews[i] >.5:
    count +=1
#     print (i)
#     print(predict_comments[i])
#     print (test_df_pews[i])
print(np.mean(test_df_pews))
print(count)

# print(test_df_pews.describe())
# test_df_pews
# valid_preds_pews[0:100]

test_df_pews[0:100]