{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/nvidiaapex/repository/NVIDIA-apex-39e153a\"))\n#print(os.listdir(\"../input/glove-global-vectors-for-word-representation\"))\n#print(os.listdir(\"../input/jigsaw-unintended-bias-in-toxicity-classification\"))\n#print(os.listdir(\"../input/fasttext-crawl-300d-2m\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['.gitignore', 'LICENSE', 'tests', 'setup.py', '.nojekyll', 'README.md', 'docs', 'csrc', 'examples', 'apex']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing Nvidia Apex\n! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a","execution_count":2,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pip/_internal/commands/install.py:207: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n  cmdoptions.check_install_build_global(options)\nCreated temporary directory: /tmp/pip-ephem-wheel-cache-y39f49cc\nCreated temporary directory: /tmp/pip-req-tracker-9iucl_jo\nCreated requirements tracker '/tmp/pip-req-tracker-9iucl_jo'\nCreated temporary directory: /tmp/pip-install-at1royp7\nProcessing /kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\n  Created temporary directory: /tmp/pip-req-build-mshifpeh\n  Added file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a to build tracker '/tmp/pip-req-tracker-9iucl_jo'\n    Running setup.py (path:/tmp/pip-req-build-mshifpeh/setup.py) egg_info for package from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\n    Running command python setup.py egg_info\n    torch.__version__  =  1.0.1.post2\n    running egg_info\n    creating pip-egg-info/apex.egg-info\n    writing pip-egg-info/apex.egg-info/PKG-INFO\n    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n    reading manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n  Source in /tmp/pip-req-build-mshifpeh has version 0.1, which satisfies requirement apex==0.1 from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\n  Removed apex==0.1 from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a from build tracker '/tmp/pip-req-tracker-9iucl_jo'\nInstalling collected packages: apex\n  Created temporary directory: /tmp/pip-record-mi0r83uq\n  Running setup.py install for apex ... \u001b[?25l    Running command /opt/conda/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-req-build-mshifpeh/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" --cpp_ext --cuda_ext install --record /tmp/pip-record-mi0r83uq/install-record.txt --single-version-externally-managed --compile\n    torch.__version__  =  1.0.1.post2\n\n    Compiling cuda extensions with\n    nvcc: NVIDIA (R) Cuda compiler driver\n    Copyright (c) 2005-2018 NVIDIA Corporation\n    Built on Sat_Aug_25_21:08:01_CDT_2018\n    Cuda compilation tools, release 10.0, V10.0.130\n    from /usr/local/cuda/bin\n\n    Pytorch binaries were compiled with Cuda 10.0.130\n\n    running install\n    running build\n    running build_py\n    creating build\n    creating build/lib.linux-x86_64-3.6\n    creating build/lib.linux-x86_64-3.6/apex\n    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n    creating build/lib.linux-x86_64-3.6/apex/normalization\n    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n    creating build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n    creating build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    creating build/lib.linux-x86_64-3.6/apex/optimizers\n    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n    creating build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    running build_ext\n    building 'apex_C' extension\n    creating build/temp.linux-x86_64-3.6\n    creating build/temp.linux-x86_64-3.6/csrc\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/opt/conda/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n    building 'amp_C' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n","name":"stdout"},{"output_type":"stream","text":"    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n    building 'fused_adam_cuda' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n    building 'syncbn' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n    building 'fused_layer_norm_cuda' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n    running install_lib\n    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    creating /opt/conda/lib/python3.6/site-packages/apex\n    creating /opt/conda/lib/python3.6/site-packages/apex/normalization\n    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /opt/conda/lib/python3.6/site-packages/apex/normalization\n    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/normalization\n    creating /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    creating /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    creating /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    creating /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\n    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\n    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\n    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex\n    creating /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    creating /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    creating /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    creating /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/compat.py to compat.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/amp.py to amp.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n","name":"stdout"},{"output_type":"stream","text":"    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/opt.py to opt.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/utils.py to utils.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/handle.py to handle.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/models.py to models.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n    running install_egg_info\n    running egg_info\n    creating apex.egg-info\n    writing apex.egg-info/PKG-INFO\n    writing dependency_links to apex.egg-info/dependency_links.txt\n    writing top-level names to apex.egg-info/top_level.txt\n    writing manifest file 'apex.egg-info/SOURCES.txt'\n    reading manifest file 'apex.egg-info/SOURCES.txt'\n    writing manifest file 'apex.egg-info/SOURCES.txt'\n    Copying apex.egg-info to /opt/conda/lib/python3.6/site-packages/apex-0.1-py3.6.egg-info\n    running install_scripts\n    writing list of installed files to '/tmp/pip-record-mi0r83uq/install-record.txt'\ndone\n\u001b[?25h  Removing source in /tmp/pip-req-build-mshifpeh\nSuccessfully installed apex-0.1\nCleaning up...\nRemoved build tracker '/tmp/pip-req-tracker-9iucl_jo'\n1 location(s) to search for versions of pip:\n* https://pypi.org/simple/pip/\nGetting page https://pypi.org/simple/pip/\nStarting new HTTPS connection (1): pypi.org:443\nCould not fetch URL https://pypi.org/simple/pip/: connection error: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f79c2f9d4a8>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)) - skipping\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport pkg_resources\nimport seaborn as sns\nimport time\nimport scipy.stats as stats\nimport gc\nimport re\nimport operator \nimport sys\nfrom sklearn import metrics\nfrom sklearn import model_selection\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom nltk.stem import PorterStemmer\nfrom sklearn.metrics import roc_auc_score\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom tqdm import tqdm, tqdm_notebook\nimport os\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport warnings\nwarnings.filterwarnings(action='once')\nimport pickle\nfrom apex import amp\nimport shutil","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndevice=torch.device('cuda')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 220\nSEED = 1234\nEPOCHS = 1\nData_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification\"\nInput_dir = \"../input\"\nWORK_DIR = \"../working/\"\nnum_to_load=1000000                         #Train size to match time limit\nvalid_size= 100000                          #Validation Size\nTOXICITY_COLUMN = 'target'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add the Bart Pytorch repo to the PATH\n# using files from: https://github.com/huggingface/pytorch-pretrained-BERT\npackage_dir_a = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\nsys.path.insert(0, package_dir_a)\n\nfrom pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\n","execution_count":6,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n  return f(*args, **kwds)\n/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:5201: ResourceWarning: unclosed file <_io.TextIOWrapper name='/tmp/.keras/keras.json' mode='r' encoding='UTF-8'>\n  _config = json.load(open(_config_path))\n/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Translate model from tensorflow to pytorch\nBERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\nconvert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n    BERT_MODEL_PATH + 'bert_model.ckpt',\nBERT_MODEL_PATH + 'bert_config.json',\nWORK_DIR + 'pytorch_model.bin')\n\nshutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')","execution_count":7,"outputs":[{"output_type":"stream","text":"Building PyTorch model from configuration: {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"max_position_embeddings\": 512,\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 30522\n}\n\nConverting TensorFlow checkpoint from /kaggle/input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/bert_model.ckpt\nLoading TF weight bert/embeddings/LayerNorm/beta with shape [768]\nLoading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\nLoading TF weight bert/embeddings/position_embeddings with shape [512, 768]\nLoading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\nLoading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\nLoading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n","name":"stdout"},{"output_type":"stream","text":"Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/pooler/dense/bias with shape [768]\nLoading TF weight bert/pooler/dense/kernel with shape [768, 768]\nLoading TF weight cls/predictions/output_bias with shape [30522]\nLoading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\nLoading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\nLoading TF weight cls/predictions/transform/dense/bias with shape [768]\nLoading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\nLoading TF weight cls/seq_relationship/output_bias with shape [2]\nLoading TF weight cls/seq_relationship/output_weights with shape [2, 768]\nInitialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\nInitialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\nInitialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\nInitialize PyTorch weight ['cls', 'predictions', 'output_bias']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\nInitialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\nInitialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\nSave PyTorch model to ../working/pytorch_model.bin\n","name":"stdout"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"'../working/bert_config.json'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../working\")","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['__notebook_source__.ipynb',\n 'bert_config.json',\n 'pytorch_model.bin',\n '.ipynb_checkpoints']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the Bert configuration file\nfrom pytorch_pretrained_bert import BertConfig\n\nbert_config = BertConfig('../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'+'bert_config.json')\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the lines to BERT format\n# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\ndef convert_lines(example, max_seq_length,tokenizer):\n    max_seq_length -=2\n    all_tokens = []\n    longer = 0\n    for text in tqdm_notebook(example):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>max_seq_length:\n            tokens_a = tokens_a[:max_seq_length]\n            longer += 1\n        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n        all_tokens.append(one_token)\n    print(longer)\n    return np.array(all_tokens)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\ntrain_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\")).sample(num_to_load+valid_size,random_state=SEED)\nprint('loaded %d records' % len(train_df))\n\n# Make sure all comment_text values are strings\ntrain_df['comment_text'] = train_df['comment_text'].astype(str) \n\nsequences = convert_lines(train_df[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\ntrain_df=train_df.fillna(0)\n# List all identities\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\ny_columns=['target']\n\ntrain_df = train_df.drop(['comment_text'],axis=1)\n# convert target to 0,1\ntrain_df['target']=(train_df['target']>=0.5).astype(float)","execution_count":12,"outputs":[{"output_type":"stream","text":"loaded 1100000 records\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1100000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f366c709c24f17828139691a29e0ad"}},"metadata":{}},{"output_type":"stream","text":"\n24678\nCPU times: user 22min 37s, sys: 22.7 s, total: 22min 59s\nWall time: 22min 50s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = sequences[:num_to_load]                \ny = train_df[y_columns].values[:num_to_load]\nX_val = sequences[num_to_load:]                \ny_val = train_df[y_columns].vlalues[num_to_load:]\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=train_df.tail(valid_size).copy()\ntrain_df=train_df.head(num_to_load)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_model_file = \"bert_pytorch.bin\"\n\nlr=2e-5\nbatch_size = 32\naccumulation_steps=1\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\nmodel = BertForSequenceClassification.from_pretrained(\"../working\",cache_dir=None,num_labels=len(y_columns))\nmodel.zero_grad()\nmodel = model.to(device)\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n    ]\ntrain = train_dataset\n\nnum_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n\noptimizer = BertAdam(optimizer_grouped_parameters,\n                     lr=lr,\n                     warmup=0.05,\n                     t_total=num_train_optimization_steps)\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\nmodel=model.train()\n\ntq = tqdm_notebook(range(EPOCHS))\nfor epoch in tq:\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    avg_loss = 0.\n    avg_accuracy = 0.\n    lossf=None\n    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n    for i,(x_batch, y_batch) in tk0:\n        optimizer.zero_grad()\n        y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n            optimizer.step()                            # Now we can do an optimizer step\n            optimizer.zero_grad()\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()\n        else:\n            lossf = loss.item()\n        tk0.set_postfix(loss = lossf)\n        avg_loss += loss.item() / len(train_loader)\n        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n\n\ntorch.save(model.state_dict(), output_model_file)\n","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"<torch._C.Generator at 0x7f7a68caedf0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cfd190cbc6d47f7a57f0f6d2e569e77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=31250), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c938ceba1a0d4e9ba3f79b35ea7d6c5c"}},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run validation\n# The following 2 lines are not needed but show how to download the model for prediction\nmodel = BertForSequenceClassification(bert_config,num_labels=len(y_columns))\nmodel.load_state_dict(torch.load(output_model_file ))\nmodel.to(device)\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.eval()\nvalid_preds = np.zeros((len(X_val)))\nvalid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\nvalid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n\ntk0 = tqdm_notebook(valid_loader)\nfor i,(x_batch,)  in enumerate(tk0):\n    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From baseline kernel\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]>0.5\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n\ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n\n\n\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]>0.5]\n    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nMODEL_NAME = 'model1'\ntest_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\nTOXICITY_COLUMN = 'target'\nbias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\nbias_metrics_df\nget_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}