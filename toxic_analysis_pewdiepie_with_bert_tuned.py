# -*- coding: utf-8 -*-
"""Toxic analysis pewdiepie with Bert tuned.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P4C4WjRn2R99Hmw-ETlu_WPX7oeCHd0D
"""

from google.colab import drive
drive.mount('/content/gdrive')

import json
with open('/content/gdrive/My Drive/Colab Notebooks/jigsaw-unintended-bias-in-toxicity-classification/comments_videos_pewdiepie_4000.json') as json_data:
  data = json.load(json_data)

!pip install pytorch-pretrained-bert

# Converting the lines to BERT format
# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming
from tqdm import tqdm, tqdm_notebook
import numpy as np
def convert_lines(example, max_seq_length,tokenizer):
    max_seq_length -=2
    all_tokens = []
    longer = 0
    for text in tqdm_notebook(example):
        tokens_a = tokenizer.tokenize(text)
        if len(tokens_a)>max_seq_length:
            tokens_a = tokens_a[:max_seq_length]
            longer += 1
        one_token = tokenizer.convert_tokens_to_ids(["[CLS]"]+tokens_a+["[SEP]"])+[0] * (max_seq_length - len(tokens_a))
        all_tokens.append(one_token)
    print(longer)
    return np.array(all_tokens)

import torch.utils.data
def get_video_predictions(X_pew):
  for param in model.parameters():
      param.requires_grad=False
  model.eval()
  valid_preds_pews = np.zeros((len(X_pew)))
  valid_pews = torch.utils.data.TensorDataset(torch.tensor(X_pew,dtype=torch.long))
  valid_loader_pews = torch.utils.data.DataLoader(valid_pews, batch_size=32, shuffle=False)

  tk0 = tqdm_notebook(valid_loader_pews)
  for i,(x_batch,)  in enumerate(tk0):
      pred_pews = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)
      valid_preds_pews[i*32:(i+1)*32]=pred_pews[:,0].detach().cpu().squeeze().numpy()
  test_df_pews=torch.sigmoid(torch.tensor(valid_preds_pews)).numpy()
  return test_df_pews

import torch
from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification
path = "/content/gdrive/My Drive/Colab Notebooks/bert_pytorch.bin"
y_columns=['target']
device=torch.device('cuda')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=len(y_columns))
model.load_state_dict(torch.load(path))
model.to(device)

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

videos_results = []
MAX_SEQUENCE_LENGTH = 128
for video in tqdm_notebook(data):  
  comments = video["comments"]
  X_pew = convert_lines(comments,MAX_SEQUENCE_LENGTH,tokenizer)
  predictions = get_video_predictions(X_pew)
  mean_prediction = np.mean(predictions)
  toxic_amount = len([tox for tox in predictions if tox > 0.5])
  vid_results = {
      "video_id":video["videoId"],
      "total_comments": len(predictions),
      "mean_toxicity":mean_prediction,
      "toxic_amount":toxic_amount ,
      "comments":comments,
      "predictions":predictions      
  }
  videos_results.append(vid_results)

import json

with open('/content/gdrive/My Drive/Colab Notebooks/comments_toxicity_analysed_pewdiepie_4000.json', 'w') as outfile:  
    json.dump(comments_list_per_vid, outfile, indent=4)